{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0412068f",
   "metadata": {},
   "source": [
    "<center><h1>Feature Extractor</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "768f1738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from IPython.display import Audio, display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "f2ccff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"challengeA_data\"\n",
    "TRAIN_PATH = \"challengeA_data/train\"\n",
    "TEST_PATH = \"challengeA_data/test\"\n",
    "TRAIN_METADATA_PATH = \"challengeA_data/2022challengeA_train_modified.csv\"\n",
    "TEST_METADATA_PATH = \"challengeA_data/2022challengeA_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e8069e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>encoded_emotion</th>\n",
       "      <th>origin</th>\n",
       "      <th>duration</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>n_channels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08b0b344-3f9d-40a4-a275-424877a6cc3f.wav</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "      <td>tess</td>\n",
       "      <td>1.781068</td>\n",
       "      <td>24414.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47e77950-a2d6-4abc-9bba-343f28bf9bb7.wav</td>\n",
       "      <td>sadness</td>\n",
       "      <td>5</td>\n",
       "      <td>ravdess</td>\n",
       "      <td>3.937271</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a42b6fba-c7b2-4e62-a735-5dc522efeb9b.wav</td>\n",
       "      <td>disgust</td>\n",
       "      <td>1</td>\n",
       "      <td>crema</td>\n",
       "      <td>2.268937</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0db38767-1286-42c6-925f-b69cf82fb6d2.wav</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>crema</td>\n",
       "      <td>3.203187</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e59e47b7-f7ed-4c68-a03d-c059fc48d7a0.wav</td>\n",
       "      <td>fear</td>\n",
       "      <td>2</td>\n",
       "      <td>crema</td>\n",
       "      <td>2.202187</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    file_id  emotion  encoded_emotion  \\\n",
       "0  08b0b344-3f9d-40a4-a275-424877a6cc3f.wav    angry                0   \n",
       "1  47e77950-a2d6-4abc-9bba-343f28bf9bb7.wav  sadness                5   \n",
       "2  a42b6fba-c7b2-4e62-a735-5dc522efeb9b.wav  disgust                1   \n",
       "3  0db38767-1286-42c6-925f-b69cf82fb6d2.wav  neutral                4   \n",
       "4  e59e47b7-f7ed-4c68-a03d-c059fc48d7a0.wav     fear                2   \n",
       "\n",
       "    origin  duration  sample_rate  n_channels  \n",
       "0     tess  1.781068      24414.0           1  \n",
       "1  ravdess  3.937271      48000.0           1  \n",
       "2    crema  2.268937      16000.0           1  \n",
       "3    crema  3.203187      16000.0           1  \n",
       "4    crema  2.202187      16000.0           1  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_METADATA_PATH, index_col=[0])\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e7ab6931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>origin</th>\n",
       "      <th>predicted_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>030472df-9d70-4d76-a1a5-acb4c33537d3.wav</td>\n",
       "      <td>crema</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ac4720de-e0d9-4667-86a7-4236d410ed25.wav</td>\n",
       "      <td>crema</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>264928af-cb15-4125-abf7-9408369d83b2.wav</td>\n",
       "      <td>crema</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2233ce2b-35ae-483c-9397-1058f681b6ef.wav</td>\n",
       "      <td>crema</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>472aa1eb-b4dc-452c-84b7-934ed61285da.wav</td>\n",
       "      <td>crema</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    file_id origin  predicted_emotion\n",
       "0  030472df-9d70-4d76-a1a5-acb4c33537d3.wav  crema                NaN\n",
       "1  ac4720de-e0d9-4667-86a7-4236d410ed25.wav  crema                NaN\n",
       "2  264928af-cb15-4125-abf7-9408369d83b2.wav  crema                NaN\n",
       "3  2233ce2b-35ae-483c-9397-1058f681b6ef.wav  crema                NaN\n",
       "4  472aa1eb-b4dc-452c-84b7-934ed61285da.wav  crema                NaN"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(TEST_METADATA_PATH, index_col=[0])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "9bffbe35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'angry',\n",
       " 1: 'disgust',\n",
       " 2: 'fear',\n",
       " 3: 'happy',\n",
       " 4: 'neutral',\n",
       " 5: 'sadness',\n",
       " 6: 'surprise'}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions = sorted(train_df[\"emotion\"].unique())\n",
    "emotion_encoder = dict(zip(emotions, np.arange(7)))\n",
    "emotion_decoder = dict(zip(list(emotion_encoder.values()), list(emotion_encoder.keys())))\n",
    "emotion_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c5dec182",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Util:\n",
    "    def __init__(self, path, df, sr, n_fft, hop_length, n_mfcc=13, norm_method=\"min_max\"):\n",
    "        self.sr = sr\n",
    "        self.path = path \n",
    "        self.df = df\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.norm_method = norm_method\n",
    "        self.n_mfcc = n_mfcc\n",
    "    \n",
    "    def get_waveform(self, waveform_file):\n",
    "        waveform_path = os.path.join(self.path, waveform_file)\n",
    "        waveform, _ = librosa.load(waveform_path, sr=self.sr)\n",
    "\n",
    "        return waveform\n",
    "            \n",
    "    def fix_length(self, array, target_length):\n",
    "        \"\"\"Truncates to obtain the middle of an array or pads an array with zeros\n",
    "        to achieve a target length.\n",
    "            :param np.ndarray array: Either a waveform or gram.\n",
    "            :param int target_length: The target length in number of samples, number of frames.\n",
    "        \"\"\"\n",
    "        assert array.ndim == 1 or array.ndim == 2, f\"This function does not accommodate fixing the length\\\n",
    "        of an array with dimensions {array.shape}. The array must either be 1- or 2-dimensional.\"\n",
    "        \n",
    "        modified_array = array.copy()\n",
    "        \n",
    "        if array.ndim == 2:\n",
    "            # Then it must be a gram and target length should then be in number of frames\n",
    "            num_frames = array.shape[1]\n",
    "            if num_frames > target_length:\n",
    "                modified_array = Util.truncate(array, target_length)\n",
    "            elif num_frames < target_length:\n",
    "                modified_array = Util.pad_with_zeros(array, target_length)\n",
    "        elif array.ndim == 1:\n",
    "            # Then it must be a waveform and the target_length must be in number of samples.\n",
    "            num_samples = len(array)\n",
    "            if num_samples > target_length:\n",
    "                modified_array = Util.truncate(array, target_length)\n",
    "            elif num_samples < target_length:\n",
    "                modified_array = Util.pad_with_zeros(array, target_length)\n",
    "        \n",
    "        return modified_array\n",
    "    \n",
    "    @staticmethod\n",
    "    def truncate(array, target_length):\n",
    "        assert array.ndim == 1 or array.ndim == 2, f\"This function doesn't accommodate arrays with dimensions\\\n",
    "         {array.shape}. The array must either be 1- or 2-dimensional\"\n",
    "        \n",
    "        modified_array = array.copy()\n",
    "        \n",
    "        if array.ndim == 1:\n",
    "            samples_to_trunc = len(array) - target_length\n",
    "            assert samples_to_trunc > 0, \"Can't truncate an array whose length is lesser than the target length.\"\n",
    "            trunc_left = trunc_right = samples_to_trunc // 2\n",
    "            # if the number of samples to truncate is odd, then one more sample must be truncated on one of the sides.\n",
    "            # The side picked is trivial, so I pick the left arbitrarily.\n",
    "            if samples_to_trunc % 2 == 1:\n",
    "                trunc_left += 1\n",
    "\n",
    "            modified_array = array[trunc_left:len(array)-trunc_right]\n",
    "            assert len(modified_array) == target_length, f\"The length of the waveform, {len(modified_array)} is not equal\\\n",
    "            to the target number of samples, {target_length}.\"\n",
    "        elif array.ndim == 2:\n",
    "            num_frames = array.shape[1]\n",
    "            frames_to_trunc = num_frames - target_length\n",
    "            assert frames_to_trunc > 0, \"Can't truncate an array whose length is lesser than the target length.\"\n",
    "            trunc_left = trunc_right = frames_to_trunc // 2\n",
    "            # if the number of samples to truncate is odd, then one more sample must be truncated on one of the sides.\n",
    "            # The side picked is trivial, so I pick the left arbitrarily.\n",
    "            if frames_to_trunc % 2 == 1:\n",
    "                trunc_left += 1\n",
    "\n",
    "            modified_array = array[:, trunc_left:num_frames-trunc_right]\n",
    "            assert modified_array.shape[1] == target_length, f\"The length of the waveform, {modified_array.shape[1]} is not equal\\\n",
    "            to the target number of samples, {target_length}.\"\n",
    "            \n",
    "        return modified_array\n",
    "                \n",
    "    @staticmethod\n",
    "    def pad_with_zeros(array, target_length):\n",
    "        \"\"\"Pads either a waveform or gram with 0s to the target length.\n",
    "        In the case of a waveform, target_length is the target number of samples;\n",
    "        With grams, it's the target number of frames.\"\"\"\n",
    "        modified_array = array.copy()\n",
    "        if array.ndim == 2:\n",
    "            num_frames = array.shape[1]\n",
    "            num_frames_to_pad = target_length - num_frames\n",
    "            # The first tuple in the tuple of tuples indicates the number of rows of zeros\n",
    "            # to pad on top of and below the gram; the second the number of columns of zeros\n",
    "            # to place before and after.\n",
    "            npad = ((0, 0), (0, num_frames_to_pad))\n",
    "            modified_array = np.pad(array, npad)\n",
    "        elif array.ndim == 1:\n",
    "            num_samples = len(array)\n",
    "            num_samples_to_pad = target_length - num_samples\n",
    "            modified_array = np.pad(array, (0, num_samples_to_pad))\n",
    "            \n",
    "        return modified_array\n",
    "    \n",
    "    def get_specgram(self, file):\n",
    "        \"\"\"Returns the magnitudes of the fourier coefficients of a short time fourier transform.\n",
    "        Note that the coefficients have not been converted to decibels.\"\"\"\n",
    "        waveform = self.get_waveform(file)\n",
    "        \n",
    "        stft = librosa.stft(y=waveform, n_fft=self.n_fft, hop_length=self.hop_length)\n",
    "        specgram = np.abs(stft)\n",
    "        specgram = librosa.amplitude_to_db(specgram, ref=np.max)\n",
    "        \n",
    "        return specgram\n",
    "    \n",
    "    def get_mel_specgram(self, file):\n",
    "        \"\"\"Returns log-mel-spectrogram given a file name.\"\"\"\n",
    "        waveform = self.get_waveform(file)\n",
    "        mel_specgram = librosa.feature.melspectrogram(y=waveform, sr=self.sr, \n",
    "                                                      n_fft=self.n_fft, hop_length=self.hop_length)\n",
    "        mel_specgram = librosa.amplitude_to_db(mel_specgram, ref=np.max)\n",
    "        return mel_specgram\n",
    "    \n",
    "    def get_mfccs(self, file, n_mfcc=13):\n",
    "        mel_specgram = self.get_mel_specgram(file)\n",
    "        mfccs = librosa.feature.mfcc(S=mel_specgram, n_mfcc=n_mfcc)\n",
    "        \n",
    "        # discard the first coefficient\n",
    "        return mfccs[1:]\n",
    "    \n",
    "    def get_combined_mfccs(self, file):\n",
    "        mfccs = self.get_mfccs(file)\n",
    "        deltas = librosa.feature.delta(mfccs)\n",
    "        delta_deltas = librosa.feature.delta(mfccs, order=2)\n",
    "        \n",
    "        combined_mfccs = np.concatenate((mfccs, deltas, delta_deltas), axis=0)\n",
    "        return combined_mfccs\n",
    "    \n",
    "    def normalize(self, array, method=None):\n",
    "        if method == None: method = self.norm_method\n",
    "        assert method == \"min_max\" or method == \"standard\", f\"'{method}' is not a recognized normalization method.\"\n",
    "        epsilon = 1e-9\n",
    "        def normalize_(vec, method=method):\n",
    "            if method == \"min_max\":\n",
    "                return (vec - vec.min())/(vec.max()-vec.min() + epsilon)\n",
    "            elif method == \"standard\":\n",
    "                return (vec - vec.mean())/(vec.std()+epsilon)\n",
    "            \n",
    "        norm_arr = []\n",
    "        for layer in array:\n",
    "            norm_layer = normalize_(layer)\n",
    "            norm_arr.append(norm_layer)\n",
    "        \n",
    "        return np.array(norm_arr, dtype=np.float32)\n",
    "    \n",
    "    def get_label(self, file):\n",
    "        return self.df[self.df[\"file_id\"] == file][\"encoded_emotion\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c730d790",
   "metadata": {},
   "source": [
    "<h1>Saving features to file</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a5f80b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SavingUtil(Util):\n",
    "    emotions = sorted(train_df[\"emotion\"].unique())\n",
    "    emotion_encoder = dict(zip(emotions, np.arange(7)))\n",
    "    emotion_decoder = dict(zip(list(emotion_encoder.values()), list(emotion_encoder.keys())))\n",
    "    _accepted_features = [\"mel_spectrogram\", \"spectrogram\", \"mfccs\", \"combined_mfccs\"]\n",
    "    \n",
    "    def __init__(self, train_path=TRAIN_PATH,\n",
    "                 df=train_df,\n",
    "                 sr=16000, \n",
    "                 target_duration=4,\n",
    "                 n_fft=512, \n",
    "                 hop_length=512, \n",
    "                 n_mfcc=13, \n",
    "                 norm_method=\"min_max\"):\n",
    "        super().__init__(train_path=train_path, df=df, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mfcc=n_mfcc, norm_method=norm_method)\n",
    "        self.target_duration = target_duration # seconds\n",
    "        \n",
    "        # used for fixing the length of waveforms\n",
    "        self.target_samples = target_duration * sr \n",
    "        \n",
    "        # used for fixing the length of grams\n",
    "        self.target_frames = (sr * target_duration - n_fft)//hop_length + 1 \n",
    "        \n",
    "    # wrapper for Util's get_mel_specgram() method     \n",
    "    def get_mel_specgram(self, file):\n",
    "        mel_specgram = super().get_mel_specgram(file)\n",
    "        mel_specgram = super().normalize(mel_specgram, method=self.norm_method)\n",
    "        mel_specgram = super().fix_length(mel_specgram, self.target_frames)\n",
    "        return mel_specgram\n",
    "    \n",
    "    # Wrapper for Util's get_mfccs() method\n",
    "    def get_mfccs(self, file):\n",
    "        \"\"\"Gets the mfccs of the file, normalizes them, and then fixes their length.\"\"\"\n",
    "        # for some reason was causing issues when calling super().get_mfccs() so I just compute the mfccs\n",
    "        # from the spectrogram. \n",
    "        mel_specgram = super().get_mel_specgram(file)\n",
    "        mfccs = librosa.feature.mfcc(S=mel_specgram, n_mfcc=self.n_mfcc)\n",
    "        mfccs = super().normalize(mfccs, method=self.norm_method)\n",
    "        mfccs = super().fix_length(mfccs, self.target_frames)\n",
    "        \n",
    "        return mfccs[1:]\n",
    "    \n",
    "    # Wrapper for Util's get_combined_mfccs() method \n",
    "    def get_combined_mfccs(self, file):\n",
    "        # Had the same issue with this function as the one above, so I just compute the combined\n",
    "        # mfccs here as opposed to in the parent class.\n",
    "        mel_specgram = super().get_mel_specgram(file)\n",
    "        mfccs = librosa.feature.mfcc(S=mel_specgram, n_mfcc=self.n_mfcc)\n",
    "        mfccs = mfccs[1:]\n",
    "        deltas = librosa.feature.delta(mfccs)\n",
    "        delta_deltas = librosa.feature.delta(mfccs, order=2)\n",
    "        combined_mfccs = np.concatenate((mfccs, deltas, delta_deltas), axis=0)\n",
    "        combined_mfccs = super().normalize(combined_mfccs, method=self.norm_method)\n",
    "        combined_mfccs = super().fix_length(combined_mfccs, self.target_frames)\n",
    "        \n",
    "        return combined_mfccs \n",
    "        \n",
    "    def save_to_file(self, file, array, feature_save_dir, category):\n",
    "        \"\"\"Saves the file to the feature save directory as a .npy file.\n",
    "\n",
    "            :param str file: - File name with .wav extension\n",
    "            :param np.ndarray array: The array of data to be saved\n",
    "            :param str feature_save_dir: the relative path to the save directory for the features\n",
    "            :param str category: The class of the label. Used to determine in which class subdirectory the file \n",
    "                should be saved.\n",
    "        \"\"\"\n",
    "        # removing the extension\n",
    "        file = file.replace(\".wav\", \".npy\")\n",
    "\n",
    "        save_dir = os.path.join(os.getcwd(), feature_save_dir, category)\n",
    "        save_path = os.path.join(save_dir, file)\n",
    "\n",
    "        # Creates a directory for a particular feature type\n",
    "        if not os.path.isdir(feature_save_dir):\n",
    "            os.mkdir(feature_save_dir)\n",
    "\n",
    "        if not os.path.isdir(save_dir):\n",
    "            os.mkdir(save_dir)\n",
    "\n",
    "        # The absolute path must be used for saving for whatever reason.\n",
    "        np.save(save_path, array) # The format of the file is .npy, which is a binary file\n",
    "        \n",
    "    # modification of above function for testing data\n",
    "    def save_test_features_to_file(self, file, array, feature_save_dir):\n",
    "        \"\"\"Saves the file to the feature save directory as a .npy file.\n",
    "            :param str file: - File name with .wav extension\n",
    "            :param np.ndarray array: The array of data to be saved\n",
    "            :param str feature_save_dir: the relative path to the save directory for the features\n",
    "        \"\"\"\n",
    "        # removing the extension\n",
    "        file = file.replace(\".wav\", \".npy\")\n",
    "\n",
    "        save_dir = os.path.join(os.getcwd(), feature_save_dir)\n",
    "        save_path = os.path.join(save_dir, file)\n",
    "\n",
    "        # Creates a directory for a particular feature type\n",
    "        if not os.path.isdir(feature_save_dir):\n",
    "            os.mkdir(feature_save_dir)\n",
    "\n",
    "        # The absolute path must be used for saving for whatever reason.\n",
    "        np.save(save_path, array) # The format of the file is .npy, which is a binary file\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_num_files_in_directory(directory, suffix, excluded: List[str]=None):\n",
    "        total = 0\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            total += len([file for file in files if file.endswith(suffix) and not any([file.endswith(sub) for sub in excluded])])\n",
    "        return total\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_noise_files(directory, suffix, no_augmented=True):\n",
    "        total = 0\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            if no_augmented:\n",
    "                total += len([file for file in files if file.endswith(suffix) and not (file.endswith(\"_1.npy\") or file.endswith(\"_2.npy\") or file.endswith(\"_3.npy\") or file.endswith(\"_noise.npy\"))])\n",
    "            else:\n",
    "                total += len([file for file in files if file.endswith(suffix)])\n",
    "        return total\n",
    "\n",
    "    def save_files(self, files, data_path, feature_type):\n",
    "        \"\"\"Saves files in batches in case saving gets disrupted midway. It only accommodates non-augmented data.\n",
    "            - files: List of .wav file names\n",
    "            - data_path: The relative path to the feature's save directory\n",
    "            - feature_type: The type of feature to extract\n",
    "        \"\"\"\n",
    "        assert feature_type in SavingUtil._accepted_features, f\"'{feature_type}' is not a recognized feature type.\"\n",
    "        feature_save_dir = os.path.join(data_path, feature_type)\n",
    "        # sort the files so that if saving is stopped before completion, it's easy to pick up from where it left off.\n",
    "        files = sorted(files)\n",
    "        num_files = len(files)\n",
    "        excluded=[\"_1.npy\", \"_2.npy\", \"_3.npy\", \"_noise.npy\"]\n",
    "        num_files_already_processed = SavingUtil.get_num_files_in_directory(feature_save_dir, \".npy\", excluded)\n",
    "        num_files_left_to_process = num_files - num_files_already_processed\n",
    "        batch_size = 10\n",
    "        num_batches = num_files_left_to_process // batch_size\n",
    "        # if the number of batches * the batch_size doesn't capture all the data, then\n",
    "        # add an additional batch which will accommodate the leftover files\n",
    "        if num_batches * batch_size < num_files_left_to_process:\n",
    "            num_batches += 1\n",
    "        \n",
    "        files_processed = 0\n",
    "        # start processing files from the index after the last file that was processed, which is essentially\n",
    "        # the number of files already processed because of 0-based indexing.\n",
    "        for batch in range(num_batches):\n",
    "            start_index = num_files_already_processed + batch * batch_size\n",
    "            for file_index in range(start_index, min(num_files, start_index + batch_size)):\n",
    "                file = files[file_index]\n",
    "                encoded_emotion = super().get_label(file)\n",
    "                decoded_emotion = SavingUtil.emotion_decoder[encoded_emotion]\n",
    "                \n",
    "                if feature_type == \"mel_spectrogram\":\n",
    "                    features = self.get_mel_specgram(file)\n",
    "                elif feature_type == \"mfccs\":\n",
    "                    features = self.get_mfccs(file)\n",
    "                elif feature_type == \"combined_mfccs\":\n",
    "                    features = self.get_combined_mfccs(file)\n",
    "                elif feature_type == \"spectrogram\":\n",
    "                    features = self.get_spectrogram(file)\n",
    "                    \n",
    "                self.save_to_file(file, features, feature_save_dir, decoded_emotion)\n",
    "                files_processed += 1\n",
    "                \n",
    "            portion_complete = round((files_processed / num_files_left_to_process)*100, 2)\n",
    "            clear_output(wait=True)\n",
    "            display(f\"Saving files to {feature_save_dir}\" + '.'*(batch%3+1))\n",
    "            display(f\"Progress: {portion_complete}%\")\n",
    "            \n",
    "        print(\"Complete!\")\n",
    "        \n",
    "    # modification of above function for testing data\n",
    "    def save_test_files(self, files, data_path, feature_type):\n",
    "        \"\"\"Saves test files in batches in case saving gets disrupted midway. It only accommodates non-augmented data.\n",
    "            - files: List of .wav file names\n",
    "            - data_path: The relative path to the feature's save directory\n",
    "            - feature_type: The type of feature to extract\n",
    "        \"\"\"\n",
    "        assert feature_type in SavingUtil._accepted_features, f\"'{feature_type}' is not a recognized feature type.\"\n",
    "        if not os.path.isdir(os.path.join(data_path, \"test_features\")):\n",
    "            os.mkdir(os.path.join(data_path, \"test_features\"))\n",
    "        feature_save_dir = os.path.join(data_path, \"test_features\", feature_type)\n",
    "        # sort the files so that if saving is stopped before completion, it's easy to pick up from where it left off.\n",
    "        files = sorted(files)\n",
    "        num_files = len(files)\n",
    "        num_files_already_processed = SavingUtil.get_num_files_in_directory(feature_save_dir, \".npy\")\n",
    "        num_files_left_to_process = num_files - num_files_already_processed\n",
    "        batch_size = 10\n",
    "        num_batches = num_files_left_to_process // batch_size\n",
    "        # if the number of batches * the batch_size doesn't capture all the data, then\n",
    "        # add an additional batch which will accommodate the leftover files\n",
    "        if num_batches * batch_size < num_files_left_to_process:\n",
    "            num_batches += 1\n",
    "        \n",
    "        files_processed = 0\n",
    "        # start processing files from the index after the last file that was processed, which is essentially\n",
    "        # the number of files already processed because of 0-based indexing.\n",
    "        for batch in range(num_batches):\n",
    "            start_index = num_files_already_processed + batch * batch_size\n",
    "            for file_index in range(start_index, min(num_files, start_index + batch_size)):\n",
    "                file = files[file_index]\n",
    "                \n",
    "                if feature_type == \"mel_spectrogram\":\n",
    "                    features = self.get_mel_specgram(file)\n",
    "                elif feature_type == \"mfccs\":\n",
    "                    features = self.get_mfccs(file)\n",
    "                elif feature_type == \"combined_mfccs\":\n",
    "                    features = self.get_combined_mfccs(file)\n",
    "                elif feature_type == \"spectrogram\":\n",
    "                    features = self.get_spectrogram(file)\n",
    "                    \n",
    "                self.save_test_features_to_file(file, features, feature_save_dir)\n",
    "                files_processed += 1\n",
    "                \n",
    "            portion_complete = round((files_processed / num_files_left_to_process)*100, 2)\n",
    "            clear_output(wait=True)\n",
    "            display(f\"Saving files to {feature_save_dir}\" + '.'*(batch%3+1))\n",
    "            display(f\"Progress: {portion_complete}%\")\n",
    "            \n",
    "        print(\"Complete!\")\n",
    "        \n",
    "    def save_augmented_files(self, files, data_path, feature_type):\n",
    "        \"\"\"Essentially the same as the save_files() method, but it's modified to work for only augmented data – the noisy waveforms.\"\"\"\n",
    "        \"\"\"Saves files in batches in case saving gets disrupted midway.\n",
    "            - files: List of .wav file names\n",
    "            - data_path: The relative path to the feature's save directory\n",
    "            - feature_type: The type of feature to extract\n",
    "        \"\"\"\n",
    "        assert feature_type in SavingUtil._accepted_features, f\"'{feature_type}' is not a recognized feature type.\"\n",
    "        feature_save_dir = os.path.join(data_path, feature_type)\n",
    "        # sort the files so that if saving is stopped before completion, it's easy to pick up from where it left off.\n",
    "        files = sorted(files)\n",
    "        num_files = len(files)\n",
    "        num_files_already_processed = SavingUtil.get_num_files_in_directory(feature_save_dir, \"_noise.npy\")\n",
    "        num_files_left_to_process = num_files - num_files_already_processed\n",
    "        batch_size = 10\n",
    "        num_batches = num_files_left_to_process // batch_size\n",
    "        # if the number of batches * the batch_size doesn't capture all the data, then\n",
    "        # add an additional batch which will accommodate the leftover files\n",
    "        if num_batches * batch_size < num_files_left_to_process:\n",
    "            num_batches += 1\n",
    "        \n",
    "        files_processed = 0\n",
    "        # start processing files from the index after the last file that was processed, which is essentially\n",
    "        # the number of files already processed because of 0-based indexing.\n",
    "        for batch in range(num_batches):\n",
    "            start_index = num_files_already_processed + batch * batch_size\n",
    "            for file_index in range(start_index, min(num_files, start_index + batch_size)):\n",
    "                file = files[file_index]\n",
    "                encoded_emotion = super().get_label(file)\n",
    "                decoded_emotion = SavingUtil.emotion_decoder[encoded_emotion]\n",
    "                \n",
    "                if feature_type == \"mel_spectrogram\":\n",
    "                    features = self.get_mel_specgram(file)\n",
    "                elif feature_type == \"mfccs\":\n",
    "                    features = self.get_mfccs(file)\n",
    "                elif feature_type == \"combined_mfccs\":\n",
    "                    features = self.get_combined_mfccs(file)\n",
    "                elif feature_type == \"spectrogram\":\n",
    "                    features = self.get_spectrogram(file)\n",
    "                    \n",
    "                # Adding in the suffix _noise so that the file can be differentiated from the original data\n",
    "                # when saved to file. \n",
    "                file = file.replace(\".wav\", \"\") + \"_noise\" + \".wav\"\n",
    "                self.save_to_file(file, features, feature_save_dir, decoded_emotion)\n",
    "                files_processed += 1\n",
    "                \n",
    "            portion_complete = round((files_processed / num_files_left_to_process)*100, 2)\n",
    "            clear_output(wait=True)\n",
    "            display(f\"Saving files to {feature_save_dir}\" + '.'*(batch%3+1))\n",
    "            display(f\"Progress: {portion_complete}%\")\n",
    "            \n",
    "        print(\"Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226f15e2",
   "metadata": {},
   "source": [
    "<h3>Mel-spectrograms</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "0442f97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "files = list(train_df[\"file_id\"])\n",
    "util = SavingUtil()\n",
    "feature_type = \"mel_spectrogram\"\n",
    "util.save_files(files, DATA_PATH, feature_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "07cc794a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saving files to challengeA_data/test_features/mel_spectrogram.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Progress: 100.0%'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "# testing data\n",
    "test_files = list(test_df[\"file_id\"])\n",
    "util = SavingUtil(TEST_PATH)\n",
    "feature_type = \"mel_spectrogram\"\n",
    "util.save_test_files(test_files, DATA_PATH, feature_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e14a237",
   "metadata": {},
   "source": [
    "<h3>MFCCs</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "b804a9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saving files to challengeA_data/mfccs...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Progress: 100.0%'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "files = list(train_df[\"file_id\"])\n",
    "util = SavingUtil()\n",
    "feature_type = \"mfccs\"\n",
    "util.save_files(files, DATA_PATH, feature_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61f931",
   "metadata": {},
   "source": [
    "<h3>MFCCs with deltas and delta-deltas</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "28ffa1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saving files to challengeA_data/combined_mfccs...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Progress: 100.0%'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "files = list(train_df[\"file_id\"])\n",
    "util = SavingUtil()\n",
    "feature_type = \"combined_mfccs\"\n",
    "util.save_files(files, DATA_PATH, feature_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d07427",
   "metadata": {},
   "source": [
    "<h3>Extracting mel-spectrograms from the augmented data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f6ec9f",
   "metadata": {},
   "source": [
    "In the data augmentation section, I created some examples from the raw audio by adding noise. I want to convert those audio files into mel-spectrograms, so that they can be loaded efficiently in the final pipeline. I will make some modifications to the SavingUtil.savefiles() method so that this can be achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "552de0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saving files to challengeA_data/mel_spectrogram...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Progress: 100.0%'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"challengeA_data/train/augmented_data/*.wav\")\n",
    "files = [file.split('/')[-1] for file in files]\n",
    "util = SavingUtil()\n",
    "feature_type = \"mel_spectrogram\"\n",
    "util.save_augmented_files(files, DATA_PATH, feature_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee4ae2c",
   "metadata": {},
   "source": [
    "<h1>Extracting static features</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6de4f2",
   "metadata": {},
   "source": [
    "<h2>Training data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd08c225",
   "metadata": {},
   "source": [
    "This feature extraction method is a modification of a feature extraction method from [this](https://github.com/Renovamen/Speech-Emotion-Recognition) github page. <br>\n",
    "<br>\n",
    "The idea of using mel-energy spectrum dynamic coefficients came from [this](https://www.researchgate.net/publication/43785303_Speech_Emotion_Recognition_Using_Support_Vector_Machines) paper; and the use of the fundamental frequency from [this](https://ieeexplore.ieee.org/document/6512793)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "89410dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(X, sample_rate: float) -> np.ndarray:\n",
    "    \"\"\"X is an amplitude time series\"\"\"\n",
    "    frame_length = 512\n",
    "    hop_length = frame_length // 4\n",
    "    ext_features = {}\n",
    "    stft = np.abs(librosa.stft(X, n_fft=frame_length, hop_length=hop_length))\n",
    "\n",
    "    pitches, magnitudes = librosa.piptrack(y=X, sr=sample_rate, S=stft, fmin=70, fmax=400)\n",
    "    pitch = []\n",
    "    for i in range(magnitudes.shape[1]):\n",
    "        index = magnitudes[:, 1].argmax()\n",
    "        pitch.append(pitches[index, i])\n",
    "\n",
    "    pitch_tuning_offset = librosa.pitch_tuning(pitches)\n",
    "    pitchmean = np.mean(pitch)\n",
    "    pitchstd = np.std(pitch)\n",
    "    pitchmax = np.max(pitch)\n",
    "    pitchmin = np.min(pitch)\n",
    "    ext_features[\"pitch_mean\"] = pitchmean\n",
    "    ext_features[\"pitch_std\"] = pitchstd\n",
    "    ext_features[\"pitch_max\"] = pitchmax\n",
    "    ext_features[\"pitch_min\"] = pitchmin\n",
    "    \n",
    "    # mean fundamental frequency\n",
    "    f0 = librosa.yin(X, sr = sr, fmin = librosa.note_to_hz('C2'), fmax= librosa.note_to_hz('C7'), frame_length=512)\n",
    "    f0_mean = np.mean(f0)\n",
    "    ext_features[\"f0_mean\"] = f0_mean\n",
    "\n",
    "    cent = librosa.feature.spectral_centroid(y=X, sr=sample_rate)\n",
    "    cent = cent / np.sum(cent)\n",
    "    meancent = np.mean(cent)\n",
    "    stdcent = np.std(cent)\n",
    "    maxcent = np.max(cent)\n",
    "    ext_features[\"cent_mean\"] = meancent\n",
    "    ext_features[\"cent_std\"] = stdcent\n",
    "    ext_features[\"cent_max\"] = maxcent\n",
    "\n",
    "    flatness = np.mean(librosa.feature.spectral_flatness(y=X))\n",
    "    ext_features[\"flatness\"] = flatness\n",
    "    \n",
    "    mfccs = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
    "    mfcc_mean = np.mean(mfccs.T, axis=0)\n",
    "    for i, val in enumerate(mfcc_mean): ext_features[\"mfcc_mean_\"+str(i)] = val\n",
    "    mfccsstd = np.std(mfccs.T, axis=0)\n",
    "    for i, val in enumerate(mfccsstd): ext_features[\"mfcc_std_\"+str(i)] = val\n",
    "    mfccmax = np.max(mfccs.T, axis=0)\n",
    "    for i, val in enumerate(mfccmax): ext_features[\"mfcc_max_\"+str(i)] = val\n",
    "        \n",
    "    # Mel-energy spectrum dynamic coefficients. From DOI:10.1007/978-3-642-21402-8_35\n",
    "    medc = np.mean(mfccs, axis=1)\n",
    "    for i, val in enumerate(medc): ext_features[\"medc_\"+str(i)] = val\n",
    "    medc_deltas = librosa.feature.delta(medc)\n",
    "    for i, val in enumerate(medc_deltas): ext_features[\"medc_delta1_\"+str(i)] = val\n",
    "    medc_delta_deltas = librosa.feature.delta(medc, order=2)\n",
    "    for i, val in enumerate(medc_delta_deltas): ext_features[\"medc_delta2_\"+str(i)] = val\n",
    "\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    for i, val in enumerate(chroma): ext_features[\"chroma_\"+str(i)] = val\n",
    "\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T, axis=0)\n",
    "    for i, val in enumerate(mel): ext_features[\"mel_\"+str(i)] = val\n",
    "\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T, axis=0)\n",
    "    for i, val in enumerate(contrast): ext_features[\"contrast_\"+str(i)] = val\n",
    "\n",
    "    zerocr = np.mean(librosa.feature.zero_crossing_rate(X))\n",
    "    ext_features[\"zero_crossing_rate\"] = zerocr\n",
    "\n",
    "    S, phase = librosa.magphase(stft)\n",
    "    meanMagnitude = np.mean(S)\n",
    "    ext_features[\"magnitude_mean\"] = meanMagnitude\n",
    "    stdMagnitude = np.std(S)\n",
    "    ext_features[\"magnitude_std\"] = stdMagnitude\n",
    "    maxMagnitude = np.max(S)\n",
    "    ext_features[\"magnitude_max\"] = maxMagnitude\n",
    "\n",
    "    rms = librosa.feature.rms(S=S, frame_length=frame_length, hop_length=hop_length)[0]\n",
    "    meanrms = np.mean(rms)\n",
    "    ext_features[\"rms_mean\"] = meanrms\n",
    "    stdrms = np.std(rms)\n",
    "    ext_features[\"rms_std\"] = stdrms\n",
    "    maxrms = np.max(rms)\n",
    "    ext_features[\"rms_max\"] = maxrms\n",
    "    \n",
    "    return ext_features\n",
    "\n",
    "def get_label(file, df):\n",
    "    return df[df[\"file_id\"] == file][\"encoded_emotion\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "946e4130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Extracting static features..'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Progress: 100.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = glob.glob(\"challengeA_data/train/*.wav\")\n",
    "\n",
    "df_list = []\n",
    "num_files = len(files)\n",
    "batch_size = 50\n",
    "num_batches = num_files // batch_size\n",
    "if num_batches * batch_size < num_files:\n",
    "    num_batches += 1\n",
    "files_processed = 0\n",
    "for batch in range(num_batches):\n",
    "    start_index = batch*batch_size\n",
    "    for file_index in range(start_index, min(num_files, start_index+batch_size)):\n",
    "        file = files[file_index]\n",
    "        file_id = file.split('/')[-1]\n",
    "        label = get_label(file_id, train_df)\n",
    "        X, sr = librosa.load(file, sr=16000)\n",
    "        ext_features = features(X, sr)\n",
    "        ext_features[\"encoded_emotion\"] = label\n",
    "        ext_features[\"file_id\"] = file_id\n",
    "        df_list.append(ext_features)\n",
    "        files_processed += 1\n",
    "        \n",
    "    clear_output(wait=True)\n",
    "    progress = files_processed/num_files*100\n",
    "    display(f\"Extracting static features\"+'.'*(batch%3+1))\n",
    "    display(f\"Progress: {round(progress, 2)}\")\n",
    "\n",
    "ext_features_df = pd.DataFrame(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b390e27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch_mean</th>\n",
       "      <th>pitch_std</th>\n",
       "      <th>pitch_max</th>\n",
       "      <th>pitch_min</th>\n",
       "      <th>f0_mean</th>\n",
       "      <th>cent_mean</th>\n",
       "      <th>cent_std</th>\n",
       "      <th>cent_max</th>\n",
       "      <th>flatness</th>\n",
       "      <th>mfcc_mean_0</th>\n",
       "      <th>...</th>\n",
       "      <th>contrast_6</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>magnitude_mean</th>\n",
       "      <th>magnitude_std</th>\n",
       "      <th>magnitude_max</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_std</th>\n",
       "      <th>rms_max</th>\n",
       "      <th>encoded_emotion</th>\n",
       "      <th>file_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.363703</td>\n",
       "      <td>39.539577</td>\n",
       "      <td>108.381409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201.633808</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.003854</td>\n",
       "      <td>0.030538</td>\n",
       "      <td>0.009262</td>\n",
       "      <td>-264.383972</td>\n",
       "      <td>...</td>\n",
       "      <td>16.490656</td>\n",
       "      <td>0.069748</td>\n",
       "      <td>0.343575</td>\n",
       "      <td>1.960476</td>\n",
       "      <td>108.180984</td>\n",
       "      <td>0.055346</td>\n",
       "      <td>0.068585</td>\n",
       "      <td>0.396134</td>\n",
       "      <td>3</td>\n",
       "      <td>03d02c0b-599b-41ac-bcea-efce75e1a64d.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.674204</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>0.037036</td>\n",
       "      <td>0.037028</td>\n",
       "      <td>-446.079895</td>\n",
       "      <td>...</td>\n",
       "      <td>15.031881</td>\n",
       "      <td>0.109002</td>\n",
       "      <td>0.027601</td>\n",
       "      <td>0.071469</td>\n",
       "      <td>1.569534</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.009539</td>\n",
       "      <td>2</td>\n",
       "      <td>8f6d2894-bb3f-4fee-8ee6-8c6f74fa2d88.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.783173</td>\n",
       "      <td>64.267929</td>\n",
       "      <td>202.607910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.116020</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.025381</td>\n",
       "      <td>0.023962</td>\n",
       "      <td>-386.664032</td>\n",
       "      <td>...</td>\n",
       "      <td>14.833075</td>\n",
       "      <td>0.078260</td>\n",
       "      <td>0.040636</td>\n",
       "      <td>0.131825</td>\n",
       "      <td>3.759614</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.018523</td>\n",
       "      <td>1</td>\n",
       "      <td>e06de6b7-5fcc-4d1b-81ea-8e37a7e2db11.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.909268</td>\n",
       "      <td>18.647245</td>\n",
       "      <td>133.430908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>413.060910</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.007603</td>\n",
       "      <td>0.038214</td>\n",
       "      <td>0.027647</td>\n",
       "      <td>-303.695984</td>\n",
       "      <td>...</td>\n",
       "      <td>30.097169</td>\n",
       "      <td>0.201381</td>\n",
       "      <td>0.264241</td>\n",
       "      <td>1.047829</td>\n",
       "      <td>20.467342</td>\n",
       "      <td>0.033354</td>\n",
       "      <td>0.034311</td>\n",
       "      <td>0.129928</td>\n",
       "      <td>0</td>\n",
       "      <td>4557ddd7-2779-4fef-bc82-7ec3fcdb9199.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.907910</td>\n",
       "      <td>54.515553</td>\n",
       "      <td>351.490479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>573.440503</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.007923</td>\n",
       "      <td>0.030084</td>\n",
       "      <td>0.048945</td>\n",
       "      <td>-340.717773</td>\n",
       "      <td>...</td>\n",
       "      <td>29.568332</td>\n",
       "      <td>0.261274</td>\n",
       "      <td>0.174153</td>\n",
       "      <td>0.649212</td>\n",
       "      <td>19.466547</td>\n",
       "      <td>0.020545</td>\n",
       "      <td>0.021535</td>\n",
       "      <td>0.094402</td>\n",
       "      <td>0</td>\n",
       "      <td>4e61d5d1-04c3-494d-bb9b-061def5cfe7e.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10105</th>\n",
       "      <td>22.562132</td>\n",
       "      <td>61.431889</td>\n",
       "      <td>200.441757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>564.067067</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.008028</td>\n",
       "      <td>0.034278</td>\n",
       "      <td>0.040569</td>\n",
       "      <td>-320.214905</td>\n",
       "      <td>...</td>\n",
       "      <td>28.761959</td>\n",
       "      <td>0.234739</td>\n",
       "      <td>0.182952</td>\n",
       "      <td>0.644933</td>\n",
       "      <td>17.329002</td>\n",
       "      <td>0.022467</td>\n",
       "      <td>0.019401</td>\n",
       "      <td>0.075627</td>\n",
       "      <td>0</td>\n",
       "      <td>95433daf-9b23-4725-b76c-a7cb0e4a1474.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10106</th>\n",
       "      <td>24.003160</td>\n",
       "      <td>49.084866</td>\n",
       "      <td>140.544632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201.604130</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.008569</td>\n",
       "      <td>0.039060</td>\n",
       "      <td>0.035927</td>\n",
       "      <td>-350.843719</td>\n",
       "      <td>...</td>\n",
       "      <td>15.298714</td>\n",
       "      <td>0.141801</td>\n",
       "      <td>0.099290</td>\n",
       "      <td>0.316607</td>\n",
       "      <td>7.413186</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>0.009548</td>\n",
       "      <td>0.042489</td>\n",
       "      <td>5</td>\n",
       "      <td>03672751-408f-4a63-a731-756910195b97.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10107</th>\n",
       "      <td>17.383577</td>\n",
       "      <td>54.917084</td>\n",
       "      <td>202.148438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.836110</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.005121</td>\n",
       "      <td>0.042695</td>\n",
       "      <td>0.008157</td>\n",
       "      <td>-405.525604</td>\n",
       "      <td>...</td>\n",
       "      <td>13.622684</td>\n",
       "      <td>0.052512</td>\n",
       "      <td>0.040902</td>\n",
       "      <td>0.158767</td>\n",
       "      <td>6.231894</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.024115</td>\n",
       "      <td>4</td>\n",
       "      <td>a95aa915-334e-4909-813a-179cb1a48085.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10108</th>\n",
       "      <td>79.311813</td>\n",
       "      <td>105.619774</td>\n",
       "      <td>234.317245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>314.145166</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.007323</td>\n",
       "      <td>0.027025</td>\n",
       "      <td>0.048782</td>\n",
       "      <td>-326.102173</td>\n",
       "      <td>...</td>\n",
       "      <td>14.962163</td>\n",
       "      <td>0.229566</td>\n",
       "      <td>0.080395</td>\n",
       "      <td>0.219080</td>\n",
       "      <td>7.538439</td>\n",
       "      <td>0.007969</td>\n",
       "      <td>0.006542</td>\n",
       "      <td>0.037295</td>\n",
       "      <td>1</td>\n",
       "      <td>002c87b5-52b1-4d87-991a-b4d3915317b2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10109</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>501.561090</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>0.038824</td>\n",
       "      <td>0.025629</td>\n",
       "      <td>-373.652679</td>\n",
       "      <td>...</td>\n",
       "      <td>29.871544</td>\n",
       "      <td>0.158047</td>\n",
       "      <td>0.113909</td>\n",
       "      <td>0.492774</td>\n",
       "      <td>16.822651</td>\n",
       "      <td>0.016701</td>\n",
       "      <td>0.014919</td>\n",
       "      <td>0.062058</td>\n",
       "      <td>1</td>\n",
       "      <td>a7cd6061-fee6-4117-8e29-153a75136610.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10110 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pitch_mean   pitch_std   pitch_max  pitch_min     f0_mean  cent_mean  \\\n",
       "0       21.363703   39.539577  108.381409        0.0  201.633808   0.015625   \n",
       "1        0.000000    0.000000    0.000000        0.0  172.674204   0.013889   \n",
       "2       24.783173   64.267929  202.607910        0.0  155.116020   0.011494   \n",
       "3        2.909268   18.647245  133.430908        0.0  413.060910   0.015873   \n",
       "4        8.907910   54.515553  351.490479        0.0  573.440503   0.014706   \n",
       "...           ...         ...         ...        ...         ...        ...   \n",
       "10105   22.562132   61.431889  200.441757        0.0  564.067067   0.015873   \n",
       "10106   24.003160   49.084866  140.544632        0.0  201.604130   0.014085   \n",
       "10107   17.383577   54.917084  202.148438        0.0  145.836110   0.015152   \n",
       "10108   79.311813  105.619774  234.317245        0.0  314.145166   0.012658   \n",
       "10109    0.000000    0.000000    0.000000        0.0  501.561090   0.013333   \n",
       "\n",
       "       cent_std  cent_max  flatness  mfcc_mean_0  ...  contrast_6  \\\n",
       "0      0.003854  0.030538  0.009262  -264.383972  ...   16.490656   \n",
       "1      0.007211  0.037036  0.037028  -446.079895  ...   15.031881   \n",
       "2      0.005017  0.025381  0.023962  -386.664032  ...   14.833075   \n",
       "3      0.007603  0.038214  0.027647  -303.695984  ...   30.097169   \n",
       "4      0.007923  0.030084  0.048945  -340.717773  ...   29.568332   \n",
       "...         ...       ...       ...          ...  ...         ...   \n",
       "10105  0.008028  0.034278  0.040569  -320.214905  ...   28.761959   \n",
       "10106  0.008569  0.039060  0.035927  -350.843719  ...   15.298714   \n",
       "10107  0.005121  0.042695  0.008157  -405.525604  ...   13.622684   \n",
       "10108  0.007323  0.027025  0.048782  -326.102173  ...   14.962163   \n",
       "10109  0.009275  0.038824  0.025629  -373.652679  ...   29.871544   \n",
       "\n",
       "       zero_crossing_rate  magnitude_mean  magnitude_std  magnitude_max  \\\n",
       "0                0.069748        0.343575       1.960476     108.180984   \n",
       "1                0.109002        0.027601       0.071469       1.569534   \n",
       "2                0.078260        0.040636       0.131825       3.759614   \n",
       "3                0.201381        0.264241       1.047829      20.467342   \n",
       "4                0.261274        0.174153       0.649212      19.466547   \n",
       "...                   ...             ...            ...            ...   \n",
       "10105            0.234739        0.182952       0.644933      17.329002   \n",
       "10106            0.141801        0.099290       0.316607       7.413186   \n",
       "10107            0.052512        0.040902       0.158767       6.231894   \n",
       "10108            0.229566        0.080395       0.219080       7.538439   \n",
       "10109            0.158047        0.113909       0.492774      16.822651   \n",
       "\n",
       "       rms_mean   rms_std   rms_max  encoded_emotion  \\\n",
       "0      0.055346  0.068585  0.396134                3   \n",
       "1      0.002847  0.001841  0.009539                2   \n",
       "2      0.005263  0.003013  0.018523                1   \n",
       "3      0.033354  0.034311  0.129928                0   \n",
       "4      0.020545  0.021535  0.094402                0   \n",
       "...         ...       ...       ...              ...   \n",
       "10105  0.022467  0.019401  0.075627                0   \n",
       "10106  0.011161  0.009548  0.042489                5   \n",
       "10107  0.005977  0.004056  0.024115                4   \n",
       "10108  0.007969  0.006542  0.037295                1   \n",
       "10109  0.016701  0.014919  0.062058                1   \n",
       "\n",
       "                                        file_id  \n",
       "0      03d02c0b-599b-41ac-bcea-efce75e1a64d.wav  \n",
       "1      8f6d2894-bb3f-4fee-8ee6-8c6f74fa2d88.wav  \n",
       "2      e06de6b7-5fcc-4d1b-81ea-8e37a7e2db11.wav  \n",
       "3      4557ddd7-2779-4fef-bc82-7ec3fcdb9199.wav  \n",
       "4      4e61d5d1-04c3-494d-bb9b-061def5cfe7e.wav  \n",
       "...                                         ...  \n",
       "10105  95433daf-9b23-4725-b76c-a7cb0e4a1474.wav  \n",
       "10106  03672751-408f-4a63-a731-756910195b97.wav  \n",
       "10107  a95aa915-334e-4909-813a-179cb1a48085.wav  \n",
       "10108  002c87b5-52b1-4d87-991a-b4d3915317b2.wav  \n",
       "10109  a7cd6061-fee6-4117-8e29-153a75136610.wav  \n",
       "\n",
       "[10110 rows x 243 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b8903c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch_mean</th>\n",
       "      <th>pitch_std</th>\n",
       "      <th>pitch_max</th>\n",
       "      <th>pitch_min</th>\n",
       "      <th>f0_mean</th>\n",
       "      <th>cent_mean</th>\n",
       "      <th>cent_std</th>\n",
       "      <th>cent_max</th>\n",
       "      <th>flatness</th>\n",
       "      <th>mfcc_mean_0</th>\n",
       "      <th>...</th>\n",
       "      <th>contrast_6</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>magnitude_mean</th>\n",
       "      <th>magnitude_std</th>\n",
       "      <th>magnitude_max</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_std</th>\n",
       "      <th>rms_max</th>\n",
       "      <th>encoded_emotion</th>\n",
       "      <th>file_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2285.714286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>-1131.370972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>436ff098-f41f-482e-8662-ec270f535b90.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pitch_mean  pitch_std  pitch_max  pitch_min      f0_mean  cent_mean  \\\n",
       "1661         0.0        0.0        0.0        0.0  2285.714286        NaN   \n",
       "\n",
       "      cent_std  cent_max  flatness  mfcc_mean_0  ...  contrast_6  \\\n",
       "1661       NaN       NaN  1.000001 -1131.370972  ...         0.0   \n",
       "\n",
       "      zero_crossing_rate  magnitude_mean  magnitude_std  magnitude_max  \\\n",
       "1661                 0.0             0.0            0.0            0.0   \n",
       "\n",
       "      rms_mean  rms_std  rms_max  encoded_emotion  \\\n",
       "1661       0.0      0.0      0.0                5   \n",
       "\n",
       "                                       file_id  \n",
       "1661  436ff098-f41f-482e-8662-ec270f535b90.wav  \n",
       "\n",
       "[1 rows x 243 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_features_df[ext_features_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd01d560",
   "metadata": {},
   "source": [
    "There are some null values. I will impute them by using the averages of the columns. Although this method is not advisable since it can alter the variance of the dataset, using methods like regression or a KNN would be overkill since it's only one instance that will be affected; thus, it will have a negligble effect on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e60080d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-206-c1a04f929c52>:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  ext_features_df = ext_features_df.fillna(ext_features_df.mean())\n"
     ]
    }
   ],
   "source": [
    "ext_features_df = ext_features_df.fillna(ext_features_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "10bb2fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch_mean</th>\n",
       "      <th>pitch_std</th>\n",
       "      <th>pitch_max</th>\n",
       "      <th>pitch_min</th>\n",
       "      <th>f0_mean</th>\n",
       "      <th>cent_mean</th>\n",
       "      <th>cent_std</th>\n",
       "      <th>cent_max</th>\n",
       "      <th>flatness</th>\n",
       "      <th>mfcc_mean_0</th>\n",
       "      <th>...</th>\n",
       "      <th>contrast_6</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>magnitude_mean</th>\n",
       "      <th>magnitude_std</th>\n",
       "      <th>magnitude_max</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_std</th>\n",
       "      <th>rms_max</th>\n",
       "      <th>encoded_emotion</th>\n",
       "      <th>file_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pitch_mean, pitch_std, pitch_max, pitch_min, f0_mean, cent_mean, cent_std, cent_max, flatness, mfcc_mean_0, mfcc_mean_1, mfcc_mean_2, mfcc_mean_3, mfcc_mean_4, mfcc_mean_5, mfcc_mean_6, mfcc_mean_7, mfcc_mean_8, mfcc_mean_9, mfcc_mean_10, mfcc_mean_11, mfcc_mean_12, mfcc_std_0, mfcc_std_1, mfcc_std_2, mfcc_std_3, mfcc_std_4, mfcc_std_5, mfcc_std_6, mfcc_std_7, mfcc_std_8, mfcc_std_9, mfcc_std_10, mfcc_std_11, mfcc_std_12, mfcc_max_0, mfcc_max_1, mfcc_max_2, mfcc_max_3, mfcc_max_4, mfcc_max_5, mfcc_max_6, mfcc_max_7, mfcc_max_8, mfcc_max_9, mfcc_max_10, mfcc_max_11, mfcc_max_12, medc_0, medc_1, medc_2, medc_3, medc_4, medc_5, medc_6, medc_7, medc_8, medc_9, medc_10, medc_11, medc_12, medc_delta1_0, medc_delta1_1, medc_delta1_2, medc_delta1_3, medc_delta1_4, medc_delta1_5, medc_delta1_6, medc_delta1_7, medc_delta1_8, medc_delta1_9, medc_delta1_10, medc_delta1_11, medc_delta1_12, medc_delta2_0, medc_delta2_1, medc_delta2_2, medc_delta2_3, medc_delta2_4, medc_delta2_5, medc_delta2_6, medc_delta2_7, medc_delta2_8, medc_delta2_9, medc_delta2_10, medc_delta2_11, medc_delta2_12, chroma_0, chroma_1, chroma_2, chroma_3, chroma_4, chroma_5, chroma_6, chroma_7, chroma_8, chroma_9, chroma_10, chroma_11, mel_0, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 243 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_features_df[ext_features_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd56673",
   "metadata": {},
   "source": [
    "The null values have successfully been imputed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7452ec84",
   "metadata": {},
   "source": [
    "I want the file_id and the encoded emotion to be at the beginning of the dataframe, so I reverse the order of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "89a367d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>encoded_emotion</th>\n",
       "      <th>rms_max</th>\n",
       "      <th>rms_std</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>magnitude_max</th>\n",
       "      <th>magnitude_std</th>\n",
       "      <th>magnitude_mean</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>contrast_6</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_mean_0</th>\n",
       "      <th>flatness</th>\n",
       "      <th>cent_max</th>\n",
       "      <th>cent_std</th>\n",
       "      <th>cent_mean</th>\n",
       "      <th>f0_mean</th>\n",
       "      <th>pitch_min</th>\n",
       "      <th>pitch_max</th>\n",
       "      <th>pitch_std</th>\n",
       "      <th>pitch_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03d02c0b-599b-41ac-bcea-efce75e1a64d.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>0.396134</td>\n",
       "      <td>0.068585</td>\n",
       "      <td>0.055346</td>\n",
       "      <td>108.180984</td>\n",
       "      <td>1.960476</td>\n",
       "      <td>0.343575</td>\n",
       "      <td>0.069748</td>\n",
       "      <td>16.490656</td>\n",
       "      <td>...</td>\n",
       "      <td>-264.383972</td>\n",
       "      <td>0.009262</td>\n",
       "      <td>0.030538</td>\n",
       "      <td>0.003854</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>201.633808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.381409</td>\n",
       "      <td>39.539577</td>\n",
       "      <td>21.363703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8f6d2894-bb3f-4fee-8ee6-8c6f74fa2d88.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009539</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>1.569534</td>\n",
       "      <td>0.071469</td>\n",
       "      <td>0.027601</td>\n",
       "      <td>0.109002</td>\n",
       "      <td>15.031881</td>\n",
       "      <td>...</td>\n",
       "      <td>-446.079895</td>\n",
       "      <td>0.037028</td>\n",
       "      <td>0.037036</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>172.674204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e06de6b7-5fcc-4d1b-81ea-8e37a7e2db11.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018523</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>3.759614</td>\n",
       "      <td>0.131825</td>\n",
       "      <td>0.040636</td>\n",
       "      <td>0.078260</td>\n",
       "      <td>14.833075</td>\n",
       "      <td>...</td>\n",
       "      <td>-386.664032</td>\n",
       "      <td>0.023962</td>\n",
       "      <td>0.025381</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>155.116020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202.607910</td>\n",
       "      <td>64.267929</td>\n",
       "      <td>24.783173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4557ddd7-2779-4fef-bc82-7ec3fcdb9199.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129928</td>\n",
       "      <td>0.034311</td>\n",
       "      <td>0.033354</td>\n",
       "      <td>20.467342</td>\n",
       "      <td>1.047829</td>\n",
       "      <td>0.264241</td>\n",
       "      <td>0.201381</td>\n",
       "      <td>30.097169</td>\n",
       "      <td>...</td>\n",
       "      <td>-303.695984</td>\n",
       "      <td>0.027647</td>\n",
       "      <td>0.038214</td>\n",
       "      <td>0.007603</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>413.060910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.430908</td>\n",
       "      <td>18.647245</td>\n",
       "      <td>2.909268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4e61d5d1-04c3-494d-bb9b-061def5cfe7e.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094402</td>\n",
       "      <td>0.021535</td>\n",
       "      <td>0.020545</td>\n",
       "      <td>19.466547</td>\n",
       "      <td>0.649212</td>\n",
       "      <td>0.174153</td>\n",
       "      <td>0.261274</td>\n",
       "      <td>29.568332</td>\n",
       "      <td>...</td>\n",
       "      <td>-340.717773</td>\n",
       "      <td>0.048945</td>\n",
       "      <td>0.030084</td>\n",
       "      <td>0.007923</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>573.440503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>351.490479</td>\n",
       "      <td>54.515553</td>\n",
       "      <td>8.907910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    file_id  encoded_emotion   rms_max  \\\n",
       "0  03d02c0b-599b-41ac-bcea-efce75e1a64d.wav                3  0.396134   \n",
       "1  8f6d2894-bb3f-4fee-8ee6-8c6f74fa2d88.wav                2  0.009539   \n",
       "2  e06de6b7-5fcc-4d1b-81ea-8e37a7e2db11.wav                1  0.018523   \n",
       "3  4557ddd7-2779-4fef-bc82-7ec3fcdb9199.wav                0  0.129928   \n",
       "4  4e61d5d1-04c3-494d-bb9b-061def5cfe7e.wav                0  0.094402   \n",
       "\n",
       "    rms_std  rms_mean  magnitude_max  magnitude_std  magnitude_mean  \\\n",
       "0  0.068585  0.055346     108.180984       1.960476        0.343575   \n",
       "1  0.001841  0.002847       1.569534       0.071469        0.027601   \n",
       "2  0.003013  0.005263       3.759614       0.131825        0.040636   \n",
       "3  0.034311  0.033354      20.467342       1.047829        0.264241   \n",
       "4  0.021535  0.020545      19.466547       0.649212        0.174153   \n",
       "\n",
       "   zero_crossing_rate  contrast_6  ...  mfcc_mean_0  flatness  cent_max  \\\n",
       "0            0.069748   16.490656  ...  -264.383972  0.009262  0.030538   \n",
       "1            0.109002   15.031881  ...  -446.079895  0.037028  0.037036   \n",
       "2            0.078260   14.833075  ...  -386.664032  0.023962  0.025381   \n",
       "3            0.201381   30.097169  ...  -303.695984  0.027647  0.038214   \n",
       "4            0.261274   29.568332  ...  -340.717773  0.048945  0.030084   \n",
       "\n",
       "   cent_std  cent_mean     f0_mean  pitch_min   pitch_max  pitch_std  \\\n",
       "0  0.003854   0.015625  201.633808        0.0  108.381409  39.539577   \n",
       "1  0.007211   0.013889  172.674204        0.0    0.000000   0.000000   \n",
       "2  0.005017   0.011494  155.116020        0.0  202.607910  64.267929   \n",
       "3  0.007603   0.015873  413.060910        0.0  133.430908  18.647245   \n",
       "4  0.007923   0.014706  573.440503        0.0  351.490479  54.515553   \n",
       "\n",
       "   pitch_mean  \n",
       "0   21.363703  \n",
       "1    0.000000  \n",
       "2   24.783173  \n",
       "3    2.909268  \n",
       "4    8.907910  \n",
       "\n",
       "[5 rows x 243 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ext_features_df.columns.to_list()\n",
    "cols = cols[::-1] # reverse the column order\n",
    "ext_features_df = ext_features_df[cols]\n",
    "ext_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9a75a7",
   "metadata": {},
   "source": [
    "I'll now save the features as a .csv file so that they can be used both for analysis and training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "bf8ef141",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_features_df.to_csv(\"challengeA_data/ext_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8726a9d2",
   "metadata": {},
   "source": [
    "<h2>Extracting the static features from the testing data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c393b413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Extracting static features.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Progress: 100.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = glob.glob(\"challengeA_data/test/*.wav\")\n",
    "\n",
    "df_list = []\n",
    "num_files = len(files)\n",
    "batch_size = 50\n",
    "num_batches = num_files // batch_size\n",
    "if num_batches * batch_size < num_files:\n",
    "    num_batches += 1\n",
    "files_processed = 0\n",
    "for batch in range(num_batches):\n",
    "    start_index = batch*batch_size\n",
    "    for file_index in range(start_index, min(num_files, start_index+batch_size)):\n",
    "        file = files[file_index]\n",
    "        file_id = file.split('/')[-1]\n",
    "        X, sr = librosa.load(file, sr=16000)\n",
    "        ext_features = features(X, sr)\n",
    "        ext_features[\"file_id\"] = file_id\n",
    "        df_list.append(ext_features)\n",
    "        files_processed += 1\n",
    "        \n",
    "    clear_output(wait=True)\n",
    "    progress = files_processed/num_files*100\n",
    "    display(f\"Extracting static features\"+'.'*(batch%3+1))\n",
    "    display(f\"Progress: {round(progress, 2)}\")\n",
    "\n",
    "test_ext_features_df = pd.DataFrame(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "19ec5422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>rms_max</th>\n",
       "      <th>rms_std</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>magnitude_max</th>\n",
       "      <th>magnitude_std</th>\n",
       "      <th>magnitude_mean</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>contrast_6</th>\n",
       "      <th>contrast_5</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_mean_0</th>\n",
       "      <th>flatness</th>\n",
       "      <th>cent_max</th>\n",
       "      <th>cent_std</th>\n",
       "      <th>cent_mean</th>\n",
       "      <th>f0_mean</th>\n",
       "      <th>pitch_min</th>\n",
       "      <th>pitch_max</th>\n",
       "      <th>pitch_std</th>\n",
       "      <th>pitch_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75e70b60-343d-409f-a956-bf900f0539e8.wav</td>\n",
       "      <td>0.030247</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>0.006978</td>\n",
       "      <td>7.646789</td>\n",
       "      <td>0.192080</td>\n",
       "      <td>0.059084</td>\n",
       "      <td>0.095326</td>\n",
       "      <td>14.980575</td>\n",
       "      <td>15.734339</td>\n",
       "      <td>...</td>\n",
       "      <td>-369.995300</td>\n",
       "      <td>0.030664</td>\n",
       "      <td>0.033477</td>\n",
       "      <td>0.006532</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>144.252273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.727966</td>\n",
       "      <td>68.689148</td>\n",
       "      <td>41.313015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>823ca09a-648d-46ee-bfd7-069a35baeb92.wav</td>\n",
       "      <td>0.250561</td>\n",
       "      <td>0.043656</td>\n",
       "      <td>0.029509</td>\n",
       "      <td>65.521172</td>\n",
       "      <td>1.167429</td>\n",
       "      <td>0.231272</td>\n",
       "      <td>0.109998</td>\n",
       "      <td>14.094052</td>\n",
       "      <td>17.068421</td>\n",
       "      <td>...</td>\n",
       "      <td>-276.970001</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>0.033964</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>240.167107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202.795929</td>\n",
       "      <td>70.466469</td>\n",
       "      <td>31.061205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fc3342c6-5c5d-4e7d-9210-b425dfae9408.wav</td>\n",
       "      <td>0.034399</td>\n",
       "      <td>0.009672</td>\n",
       "      <td>0.009711</td>\n",
       "      <td>9.812358</td>\n",
       "      <td>0.305776</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>0.134193</td>\n",
       "      <td>31.265947</td>\n",
       "      <td>17.917684</td>\n",
       "      <td>...</td>\n",
       "      <td>-438.711243</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.050212</td>\n",
       "      <td>0.013555</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>567.144093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a458a4f0-0500-4d65-b8ad-131e21fe528e.wav</td>\n",
       "      <td>0.038927</td>\n",
       "      <td>0.005907</td>\n",
       "      <td>0.008298</td>\n",
       "      <td>8.294876</td>\n",
       "      <td>0.224092</td>\n",
       "      <td>0.054525</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>14.647235</td>\n",
       "      <td>15.893116</td>\n",
       "      <td>...</td>\n",
       "      <td>-382.502869</td>\n",
       "      <td>0.009365</td>\n",
       "      <td>0.040510</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>167.822575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.398911</td>\n",
       "      <td>36.647083</td>\n",
       "      <td>17.988691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b55ea059-c5ed-433e-9bdd-13d9ce24b3ad.wav</td>\n",
       "      <td>0.112187</td>\n",
       "      <td>0.021820</td>\n",
       "      <td>0.016809</td>\n",
       "      <td>28.510019</td>\n",
       "      <td>0.611545</td>\n",
       "      <td>0.115927</td>\n",
       "      <td>0.071067</td>\n",
       "      <td>14.089204</td>\n",
       "      <td>17.714378</td>\n",
       "      <td>...</td>\n",
       "      <td>-343.037231</td>\n",
       "      <td>0.009470</td>\n",
       "      <td>0.033004</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>200.973899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202.232788</td>\n",
       "      <td>83.071732</td>\n",
       "      <td>50.256897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 242 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    file_id   rms_max   rms_std  rms_mean  \\\n",
       "0  75e70b60-343d-409f-a956-bf900f0539e8.wav  0.030247  0.005467  0.006978   \n",
       "1  823ca09a-648d-46ee-bfd7-069a35baeb92.wav  0.250561  0.043656  0.029509   \n",
       "2  fc3342c6-5c5d-4e7d-9210-b425dfae9408.wav  0.034399  0.009672  0.009711   \n",
       "3  a458a4f0-0500-4d65-b8ad-131e21fe528e.wav  0.038927  0.005907  0.008298   \n",
       "4  b55ea059-c5ed-433e-9bdd-13d9ce24b3ad.wav  0.112187  0.021820  0.016809   \n",
       "\n",
       "   magnitude_max  magnitude_std  magnitude_mean  zero_crossing_rate  \\\n",
       "0       7.646789       0.192080        0.059084            0.095326   \n",
       "1      65.521172       1.167429        0.231272            0.109998   \n",
       "2       9.812358       0.305776        0.051465            0.134193   \n",
       "3       8.294876       0.224092        0.054525            0.056300   \n",
       "4      28.510019       0.611545        0.115927            0.071067   \n",
       "\n",
       "   contrast_6  contrast_5  ...  mfcc_mean_0  flatness  cent_max  cent_std  \\\n",
       "0   14.980575   15.734339  ...  -369.995300  0.030664  0.033477  0.006532   \n",
       "1   14.094052   17.068421  ...  -276.970001  0.033838  0.033964  0.005954   \n",
       "2   31.265947   17.917684  ...  -438.711243  0.023048  0.050212  0.013555   \n",
       "3   14.647235   15.893116  ...  -382.502869  0.009365  0.040510  0.005021   \n",
       "4   14.089204   17.714378  ...  -343.037231  0.009470  0.033004  0.003945   \n",
       "\n",
       "   cent_mean     f0_mean  pitch_min   pitch_max  pitch_std  pitch_mean  \n",
       "0   0.010870  144.252273        0.0  170.727966  68.689148   41.313015  \n",
       "1   0.014493  240.167107        0.0  202.795929  70.466469   31.061205  \n",
       "2   0.017241  567.144093        0.0    0.000000   0.000000    0.000000  \n",
       "3   0.011628  167.822575        0.0  108.398911  36.647083   17.988691  \n",
       "4   0.012658  200.973899        0.0  202.232788  83.071732   50.256897  \n",
       "\n",
       "[5 rows x 242 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = test_ext_features_df.columns\n",
    "cols = cols[::-1]\n",
    "test_ext_features_df = test_ext_features_df[cols]\n",
    "test_ext_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "76c1bdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ext_features_df.to_csv(\"challengeA_data/test_ext_features.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LoopQPrize",
   "language": "python",
   "name": "loopqprize"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
